{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "from fastapi import FastAPI, Request, HTTPException\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from fastapi.templating import Jinja2Templates\n",
    "from fastapi.responses import FileResponse, HTMLResponse\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import uvicorn\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consulta 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(year:int) -> dict:\n",
    "    # Cargar el DataFrame desde el archivo parquet\n",
    "    df = pd.read_parquet('venv/data/users_reviews_etl_comprimido.parquet')\n",
    "\n",
    "    # Filtrar las filas del DataFrame para el año proporcionado\n",
    "    df_year = df[df['date'] == int(year)]\n",
    "\n",
    "    # Contar los valores en la columna 'sentiment_analysis'\n",
    "    count_negative = (df_year['sentiment_analysis'] == 0).sum()\n",
    "    count_neutral = (df_year['sentiment_analysis'] == 1).sum()\n",
    "    count_positive = (df_year['sentiment_analysis'] == 2).sum()\n",
    "\n",
    "    # Crear un diccionario con los resultados\n",
    "    result_mapped = {\n",
    "        'Negative': count_negative,\n",
    "        'Neutral': count_neutral,\n",
    "        'Positive': count_positive\n",
    "    }\n",
    "\n",
    "    # Eliminar las claves que tengan un valor de 0\n",
    "    #result_mapped = {key: value for key, value in result_mapped.items() if value != 0}\n",
    "\n",
    "    return result_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Negative': 114, 'Neutral': 72, 'Positive': 346}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso de la función\n",
    "year = 2011\n",
    "analysis_result = sentiment_analysis(year)\n",
    "print(analysis_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consulta 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def UsersRecommend(year: int) -> List[Dict[str, Any]]:\n",
    "    # Cargar los DataFrames desde los archivos parquet\n",
    "    df_reviews = pd.read_parquet('venv/data/users_reviews_etl_comprimido.parquet')\n",
    "    df_items = pd.read_parquet('venv/data/users_items_etl_comprimido.parquet')\n",
    "    \n",
    "    # Filtrar por año y recommend=True\n",
    "    filtered_reviews = df_reviews[(df_reviews['date'] == int(year)) & (df_reviews['recommend'] == True)]\n",
    "    \n",
    "    # Obtener los tres primeros item_id con el mayor número de sentiment_analysis igual a 1 o 2\n",
    "    top_items = filtered_reviews.groupby('item_id').sum().sort_values(by='sentiment_analysis', ascending=False).head(3)\n",
    "    \n",
    "    # Obtener los nombres de los juegos correspondientes a los item_id encontrados\n",
    "    recommendations = []\n",
    "    for idx, row in top_items.iterrows():\n",
    "        # Verificar si el item_id existe en df_items\n",
    "        if idx in df_items['item_id'].values:\n",
    "            item_name = df_items.loc[df_items['item_id'] == idx, 'item_name'].iloc[0]\n",
    "            recommendations.append({\"Puesto \" + str(len(recommendations) + 1): item_name})\n",
    "        else:\n",
    "            recommendations.append({\"Puesto \" + str(len(recommendations) + 1): idx})\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso:\n",
    "year = 2009  # Año ingresado por el usuario\n",
    "recommendations = UsersRecommend(year)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consulta 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UsersNotRecommend(year:int) -> List[Dict[str, Any]]:\n",
    "    # Cargar los DataFrames desde los archivos parquet\n",
    "    df_reviews = pd.read_parquet('venv/data/users_reviews_etl_comprimido.parquet')\n",
    "    df_items = pd.read_parquet('venv/data/users_items_etl_comprimido.parquet')\n",
    "    \n",
    "    # Filtrar por año y recommend=False\n",
    "    filtered_reviews = df_reviews[(df_reviews['date'] == int(year)) & (df_reviews['recommend'] == False)]\n",
    "    \n",
    "    # Obtener los tres primeros item_id con el mayor número de sentiment_analysis igual a 0\n",
    "    top_items = filtered_reviews.groupby('item_id').sum().sort_values(by='sentiment_analysis', ascending=False).head(3)\n",
    "    \n",
    "    # Obtener los nombres de los juegos correspondientes a los item_id encontrados\n",
    "    recommendations = []\n",
    "    for idx, row in top_items.iterrows():\n",
    "        # Verificar si el item_id existe en df_items\n",
    "        if idx in df_items['item_id'].values:\n",
    "            item_name = df_items.loc[df_items['item_id'] == idx, 'item_name'].iloc[0]\n",
    "            recommendations.append({\"Puesto \" + str(len(recommendations) + 1): item_name})\n",
    "        else:\n",
    "            recommendations.append({\"Puesto \" + str(len(recommendations) + 1): idx})\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Puesto 1': 'Call Of Duty Modern Warfare 3'}, {'Puesto 2': 'Aliens Vs Predator'}, {'Puesto 3': 'Jagged Alliance Back In Action'}]\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso:\n",
    "year = 2012  # Año ingresado por el usuario\n",
    "recommendations = UsersNotRecommend(year)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consulta 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def UsersRecommend(genre: str) -> Dict[str, int]:\n",
    "    # Cargar los DataFrames\n",
    "    df_games =pd.read_parquet('venv/data/steam_games_etl_comprimido.parquet')\n",
    "    df_items = pd.read_parquet('venv/data/users_items_etl_comprimido.parquet')\n",
    "    \n",
    "    # Filtrar por género\n",
    "    genre_games = df_games[df_games['genres'].str.contains(genre, case=False)]\n",
    "    \n",
    "    # Obtener los IDs de los videojuegos del género especificado\n",
    "    genre_game_ids = genre_games['id_game'].unique()\n",
    "    \n",
    "    # Filtrar los items por los IDs de los videojuegos del género\n",
    "    genre_items = df_items[df_items['item_id'].isin(genre_game_ids)]\n",
    "    \n",
    "    # Sumar el tiempo de juego en horas para cada videojuego\n",
    "    genre_items.loc[:, 'playtime_hours'] = genre_items['playtime_forever'] / 60\n",
    "    \n",
    "    # Unir los DataFrames para obtener los años de lanzamiento de los videojuegos del género\n",
    "    merged_df = pd.merge(genre_items, df_games[['id_game', 'year_release']], left_on='item_id', right_on='id_game')\n",
    "    \n",
    "    # Agrupar por año de lanzamiento y sumar las horas jugadas\n",
    "    year_playtime = merged_df.groupby('year_release')['playtime_hours'].sum()\n",
    "    \n",
    "    # Encontrar el año con más horas jugadas\n",
    "    max_playtime_year = year_playtime.idxmax()\n",
    "    \n",
    "    # Construir el resultado final\n",
    "    result = {f\"Año de lanzamiento con más horas jugadas para Género {genre}\": max_playtime_year}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Año de lanzamiento con más horas jugadas para Género Sports': 2015}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhcat\\AppData\\Local\\Temp\\ipykernel_10144\\573753200.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genre_items.loc[:, 'playtime_hours'] = genre_items['playtime_forever'] / 60\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "genre = \"Sports\"  # Género ingresado por el usuario\n",
    "recommendation = UsersRecommend(genre)\n",
    "print(recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consulta 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UserForGenre(genre: str) -> List[Dict[str, Any]]:\n",
    "    # Cargar los DataFrames\n",
    "    df_games = pd.read_parquet('venv/data/steam_games_etl_comprimido.parquet')\n",
    "    df_items = pd.read_parquet('venv/data/users_items_etl_comprimido.parquet')\n",
    "    \n",
    "    # Filtrar por género\n",
    "    genre_games = df_games[df_games['genres'].str.contains(genre, case=False)]\n",
    "    \n",
    "    # Obtener los IDs de los videojuegos del género especificado\n",
    "    genre_game_ids = genre_games['id_game'].unique()\n",
    "    \n",
    "    # Filtrar los items por los IDs de los videojuegos del género\n",
    "    genre_items = df_items[df_items['item_id'].isin(genre_game_ids)]\n",
    "    \n",
    "    # Sumar el tiempo de juego en horas para cada videojuego y usuario\n",
    "    genre_items.loc[:, 'playtime_hours'] = genre_items['playtime_forever'] / 60\n",
    "    \n",
    "    # Agrupar por usuario y sumar las horas jugadas para cada uno\n",
    "    user_playtime = genre_items.groupby('user_id').agg({'playtime_hours': 'sum'})\n",
    "    \n",
    "    # Encontrar al usuario con más horas jugadas\n",
    "    user_with_most_playtime = user_playtime.idxmax()[0]\n",
    "    \n",
    "    # Obtener los juegos donde el usuario con más horas jugadas jugó\n",
    "    games_played_by_user = genre_items[genre_items['user_id'] == user_with_most_playtime]['item_name'].unique()\n",
    "    \n",
    "    # Volver al DataFrame df_games para cruzar con las horas jugadas por año\n",
    "    merged_df = pd.merge(df_games, genre_items, left_on='app_name', right_on='item_name')\n",
    "    \n",
    "    # Agrupar por año y sumar las horas jugadas para el usuario y género especificados\n",
    "    user_genre_year_playtime = merged_df.groupby(['user_id', 'year_release']).agg({'playtime_hours': 'sum'})\n",
    "    \n",
    "    # Obtener las horas jugadas por año para el usuario con más horas jugadas\n",
    "    if user_with_most_playtime in user_genre_year_playtime.index:\n",
    "        user_most_playtime_year = user_genre_year_playtime.loc[user_with_most_playtime].reset_index()\n",
    "    else:\n",
    "        user_most_playtime_year = pd.DataFrame(columns=['year_release', 'playtime_hours'])\n",
    "    \n",
    "    # Construir el resultado final\n",
    "    result = {\n",
    "        \"Usuario con más horas jugadas para Género {}: \".format(genre): user_with_most_playtime,\n",
    "        \"Horas jugadas\": [\n",
    "            {\"Año\": int(row['year_release']), \"Horas\": row['playtime_hours']} for index, row in user_most_playtime_year.iterrows()\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhcat\\AppData\\Local\\Temp\\ipykernel_10144\\1694948807.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genre_items.loc[:, 'playtime_hours'] = genre_items['playtime_forever'] / 60\n",
      "C:\\Users\\jhcat\\AppData\\Local\\Temp\\ipykernel_10144\\1694948807.py:22: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  user_with_most_playtime = user_playtime.idxmax()[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Usuario con más horas jugadas para Género Casual: ': 'Overwhelmer', 'Horas jugadas': [{'Año': 2012, 'Horas': 1.0833333333333333}, {'Año': 2015, 'Horas': 3982.8}]}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "genre = \"Casual\"  # Género ingresado por el usuario\n",
    "recommendation = UserForGenre(genre)\n",
    "print(recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendacion item - item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion_juego(id_game: int, df_games_path: str = 'venv/data/steam_games_etl_comprimido.parquet', df_reviews_path: str = 'venv/data/users_reviews_etl_comprimido.parquet') -> dict:\n",
    "    # Cargar DataFrames\n",
    "    df_games = pd.read_parquet(df_games_path)\n",
    "    df_reviews = pd.read_parquet(df_reviews_path)\n",
    "\n",
    "    # Obtener el género del juego ingresado\n",
    "    genres = df_games.loc[df_games['id_game'] == id_game, 'genres'].iloc[0]\n",
    "\n",
    "    # Filtrar juegos por géneros relacionados\n",
    "    related_games = df_games[df_games['genres'].apply(lambda x: any(genre in x for genre in genres))]\n",
    "\n",
    "    # Obtener los IDs de los juegos relacionados\n",
    "    related_game_ids = related_games['id_game'].tolist()\n",
    "\n",
    "    # Filtrar reviews por los juegos relacionados y que han sido recomendados\n",
    "    recommended_reviews = df_reviews[(df_reviews['item_id'].isin(related_game_ids)) & (df_reviews['recommend'] == True)]\n",
    "\n",
    "    # Obtener IDs únicos de los juegos recomendados\n",
    "    recommended_game_ids = recommended_reviews['item_id'].unique()\n",
    "\n",
    "    # Filtrar los juegos relacionados por los juegos recomendados\n",
    "    recommended_games = related_games[related_games['id_game'].isin(recommended_game_ids)]\n",
    "\n",
    "    # Crear un CountVectorizer para los géneros\n",
    "    vectorizer = CountVectorizer(tokenizer=lambda x: x.split(','))\n",
    "\n",
    "    # Obtener la matriz de géneros\n",
    "    genre_matrix = vectorizer.fit_transform(related_games['genres'])\n",
    "\n",
    "    # Calcular la similitud del coseno entre los juegos\n",
    "    similarity_matrix = cosine_similarity(genre_matrix, genre_matrix)\n",
    "\n",
    "    # Obtener el índice del juego ingresado\n",
    "    index = related_games.index[related_games['id_game'] == id_game].tolist()[0]\n",
    "\n",
    "    # Obtener las similitudes del juego ingresado con otros juegos\n",
    "    sim_scores = list(enumerate(similarity_matrix[index]))\n",
    "\n",
    "    # Ordenar los juegos por similitud\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Obtener los 5 juegos más similares excluyendo el juego ingresado\n",
    "    top_similar_games = sim_scores[1:6]\n",
    "\n",
    "    # Obtener los nombres de los juegos recomendados\n",
    "    recommended_game_names = recommended_games.loc[recommended_games['id_game'].isin([related_games.iloc[i[0]]['id_game'] for i in top_similar_games]), 'app_name'].tolist()\n",
    "\n",
    "    return {\"Juegos recomendados\": recommended_game_names}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Curso Henry\\DataPT08\\LABs\\PI_1\\PI1_MLOps_Stean\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Juegos recomendados': ['Ducktales Remastered']}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "id_game = 767400  # ID del juego ingresado por el usuario\n",
    "df_games_path = 'venv/data/steam_games_etl_comprimido.parquet'\n",
    "df_reviews_path = 'venv/data/users_reviews_etl_comprimido.parquet'\n",
    "\n",
    "recomendaciones = recomendacion_juego(id_game, df_games_path, df_reviews_path)\n",
    "print(recomendaciones)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
